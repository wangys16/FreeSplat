[2024-10-10 15:26:49,364][py.warnings][WARNING] - /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/wang/lab/freesplat_github/src/main.py +experim ...
[2024-10-10 15:26:49,398][py.warnings][WARNING] - /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21ft1k to current tf_efficientnetv2_s.in21k_ft_in1k.
  model = create_fn(
[2024-10-10 15:26:49,767][timm.models._builder][INFO] - Loading pretrained weights from Hugging Face hub (timm/tf_efficientnetv2_s.in21k_ft_in1k)
[2024-10-10 15:26:50,026][timm.models._hub][INFO] - [timm/tf_efficientnetv2_s.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
[2024-10-10 15:26:50,259][py.warnings][WARNING] - /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
[2024-10-10 15:26:50,259][py.warnings][WARNING] - /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Loading model from: /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
dataset:
    view_sampler: {'name': 'bounded', 'num_target_views': 4, 'num_context_views': 2, 'min_distance_between_context_views': 25, 'max_distance_between_context_views': 25, 'min_distance_to_context_views': 0, 'warm_up_steps': 15000, 'initial_min_distance_between_context_views': 15, 'initial_max_distance_between_context_views': 25}
    name: scannet
    roots: ['/home/wang/ssd/scannet/scannet_surn/scannet']
    make_baseline_1: False
    augment: True
    image_shape: [384, 512]
    background_color: [0.0, 0.0, 0.0]
    cameras_are_circular: False
    baseline_epsilon: 0.001
    max_fov: 100.0
    load_depth: True
    overfit_to_scene: None
    near: 0.5
    far: 15.0
model:
    encoder: {'backbone': {'name': 'efficientnet', 'model': 'efficientnet', 'd_out': 512}, 'name': 'freesplat', 'opacity_mapping': {'initial': 0.0, 'final': 0.0, 'warm_up': 1}, 'num_monocular_samples': 32, 'num_surfaces': 1, 'predict_opacity': False, 'near_disparity': 3.0, 'gaussians_per_pixel': 3, 'gaussian_adapter': {'gaussian_scale_min': 0.5, 'gaussian_scale_max': 15.0, 'sh_degree': 2, 'depth_sup': True}, 'd_feature': 128, 'epipolar_transformer': {'self_attention': {'patch_size': 4, 'num_octaves': 10, 'num_layers': 2, 'num_heads': 4, 'd_token': 128, 'd_dot': 128, 'd_mlp': 256}, 'num_octaves': 10, 'num_layers': 2, 'num_heads': 4, 'num_samples': 32, 'd_dot': 128, 'd_mlp': 256, 'downscale': 4}, 'visualizer': {'num_samples': 8, 'min_resolution': 256, 'export_ply': False}, 'apply_bounds_shim': False, 'use_epipolar_transformer': False, 'use_transmittance': False, 'load_depth': False, 'est_depth': 'cost', 'unimatch_weights_path': 'checkpoints/gmdepth-scale1-resumeflowthings-scannet-5d9d7964.pth', 'multiview_trans_attn_split': 2, 'costvolume_unet_feat_dim': 128, 'costvolume_unet_channel_mult': [1, 1, 1], 'costvolume_unet_attn_res': [], 'depth_unet_feat_dim': 64, 'depth_unet_attn_res': [], 'depth_unet_channel_mult': [1, 1, 1], 'downscale_factor': 4, 'shim_patch_size': 4, 'wo_depth_refine': False, 'wo_cost_volume': False, 'wo_backbone_cross_attn': False, 'wo_cost_volume_refine': False, 'use_epipolar_trans': False, 'num_views': 2, 'num_depth_candidates': 128}
    decoder: {'name': 'splatting_cuda'}
loss:
    mse: {'weight': 1.0}
    lpips: {'weight': 0.05, 'apply_after_step': 0}
output_dir: train_2views
wandb:
    project: pixelsplat
    entity: wangys10272910
    name: scannet
    mode: offline
    tags: ['scannet', '384x512']
mode: train
data_loader:
    train: {'num_workers': 16, 'persistent_workers': True, 'batch_size': 1, 'seed': 1234}
    test: {'num_workers': 4, 'persistent_workers': False, 'batch_size': 1, 'seed': 2345}
    val: {'num_workers': 1, 'persistent_workers': True, 'batch_size': 1, 'seed': 3456}
optimizer:
    lr: 0.0001
    warm_up_steps: 100
    cosine_lr: True
checkpointing:
    load: None
    every_n_train_steps: 10000
    save_top_k: -1
train:
    load_depth: None
    depth_mode: depth
    extended_visualization: False
    depth_sup: True
test:
    output_path: outputs/test
seed: 111123
strict: True
trainer:
    max_steps: 300001
    val_check_interval: 5000
    gradient_clip_val: 0.01
    prog_bar: True
+++++++++++++++++++++index_path: assets/evaluation_index_scannet.json
--------------------data root: /home/wang/ssd/scannet/scannet_surn/scannet
validation dataloader length: 80
validation step 0; scene = ['scene0000_01_0']; context = [[[4060, 4083]]]
[2024-10-10 15:26:52,781][py.warnings][WARNING] - /home/wang/lab/freesplat_github/src/model/encoder/common/gaussian_adapter.py:39: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  i_coords, j_coords = torch.meshgrid(torch.range(0,height-1), torch.range(0,width-1), indexing='ij')
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name    | Type                 | Params
-------------------------------------------------
0 | encoder | EncoderFreeSplat     | 50.5 M
1 | decoder | DecoderSplattingCUDA | 0
2 | losses  | ModuleList           | 0
-------------------------------------------------
50.5 M    Trainable params
0         Non-trainable params
50.5 M    Total params
202.177   Total estimated model params size (MB)
Loading model from: /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
psnr: tensor(0., device='cuda:0') lpips: tensor(0., device='cuda:0') ssim: tensor(0., device='cuda:0') mask: tensor(0, device='cuda:0')
[2024-10-10 15:26:54,202][py.warnings][WARNING] - /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
[2024-10-10 15:26:54,208][py.warnings][WARNING] - /home/wang/lab/freesplat_github/src/model/model_wrapper.py:84: RuntimeWarning: divide by zero encountered in divide
  disp_map = 1/depth_map
validation step 0; scene = ['scene0000_01_1']; context = [[[4010, 4032]]]
[2024-10-10 15:26:55,727][py.warnings][WARNING] - /home/wang/lab/freesplat_github/src/model/encoder/common/gaussian_adapter.py:39: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  i_coords, j_coords = torch.meshgrid(torch.range(0,height-1), torch.range(0,width-1), indexing='ij')
psnr: tensor(0., device='cuda:0') lpips: tensor(0., device='cuda:0') ssim: tensor(0., device='cuda:0') mask: tensor(0, device='cuda:0')
[2024-10-10 15:26:55,871][py.warnings][WARNING] - /home/wang/lab/freesplat_github/src/model/model_wrapper.py:84: RuntimeWarning: divide by zero encountered in divide
  disp_map = 1/depth_map
[2024-10-10 15:26:56,466][py.warnings][WARNING] - /home/wang/lab/freesplat_github/src/model/model_wrapper.py:710: RuntimeWarning: invalid value encountered in scalar divide
  line = line + f'{metric}=' + str((np.array(self.metrics[metric])*np.array(self.valids)).sum() / np.array(self.valids).sum()) + ' '
psnr=nan lpips=nan ssim=nan
--------------------data root: /home/wang/ssd/scannet/scannet_surn/scannet
[2024-10-10 15:26:58,374][py.warnings][WARNING] - /home/wang/lab/freesplat_github/src/model/model_wrapper.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  f"psnr = {torch.mean(torch.tensor(psnr)):.2f}"
train step 0; scene = ['scene0005_00']; context = [[[741, 762]]]; loss = 0.107316 psnr = 11.14 loss_mse = 0.077039 loss_lpips = 0.030277 gs_ratio = 0.929535
train step 10; scene = ['scene0397_01']; context = [[[878, 894]]]; loss = 0.107671 psnr = 10.04 loss_mse = 0.078614 loss_lpips = 0.029057 gs_ratio = 0.804036
train step 20; scene = ['scene0211_01']; context = [[[194, 209]]]; loss = 0.119076 psnr = 10.21 loss_mse = 0.089341 loss_lpips = 0.029735 gs_ratio = 0.570735
train step 30; scene = ['scene0029_02']; context = [[[519, 543]]]; loss = 0.129001 psnr = 12.13 loss_mse = 0.099663 loss_lpips = 0.029338 gs_ratio = 0.903369
train step 40; scene = ['scene0298_00']; context = [[[670, 686]]]; loss = 0.104808 psnr = 11.65 loss_mse = 0.075394 loss_lpips = 0.029415 gs_ratio = 0.847552
train step 50; scene = ['scene0349_01']; context = [[[1210, 1232]]]; loss = 0.101930 psnr = 11.82 loss_mse = 0.071610 loss_lpips = 0.030321 gs_ratio = 0.587102
train step 60; scene = ['scene0505_00']; context = [[[1901, 1925]]]; loss = 0.117992 psnr = 10.17 loss_mse = 0.088527 loss_lpips = 0.029465 gs_ratio = 0.802116
train step 70; scene = ['scene0188_00']; context = [[[931, 951]]]; loss = 0.106232 psnr = 11.81 loss_mse = 0.078988 loss_lpips = 0.027244 gs_ratio = 0.892807
train step 80; scene = ['scene0323_00']; context = [[[197, 215]]]; loss = 0.109445 psnr = 9.59 loss_mse = 0.082988 loss_lpips = 0.026457 gs_ratio = 0.625880
train step 90; scene = ['scene0692_04']; context = [[[252, 275]]]; loss = 0.122298 psnr = 13.18 loss_mse = 0.092618 loss_lpips = 0.029680 gs_ratio = 0.608065
train step 100; scene = ['scene0529_00']; context = [[[896, 914]]]; loss = 0.119728 psnr = 10.98 loss_mse = 0.091760 loss_lpips = 0.027968 gs_ratio = 0.654101
train step 106; scene = ['scene0020_00']; context = [[[100, 121]]]; loss = 0.099103 psnr = 10.83 loss_mse = 0.069569 loss_lpips = 0.029534 gs_ratio = 0.939512
train step 116; scene = ['scene0399_01']; context = [[[1124, 1148]]]; loss = 0.131404 psnr = 10.79 loss_mse = 0.099084 loss_lpips = 0.032320 gs_ratio = 0.920588
train step 126; scene = ['scene0313_02']; context = [[[267, 286]]]; loss = 0.067997 psnr = 15.61 loss_mse = 0.040396 loss_lpips = 0.027601 gs_ratio = 0.765292
train step 136; scene = ['scene0505_00']; context = [[[3291, 3312]]]; loss = 0.111060 psnr = 9.01 loss_mse = 0.079550 loss_lpips = 0.031510 gs_ratio = 0.843404
train step 146; scene = ['scene0029_02']; context = [[[959, 978]]]; loss = 0.082684 psnr = 10.06 loss_mse = 0.052643 loss_lpips = 0.030041 gs_ratio = 0.651062
train step 156; scene = ['scene0163_00']; context = [[[1267, 1284]]]; loss = 0.080373 psnr = 7.31 loss_mse = 0.050714 loss_lpips = 0.029659 gs_ratio = 0.742104
train step 166; scene = ['scene0092_03']; context = [[[2635, 2651]]]; loss = 0.076635 psnr = 14.60 loss_mse = 0.047589 loss_lpips = 0.029047 gs_ratio = 0.940984
train step 176; scene = ['scene0043_01']; context = [[[353, 376]]]; loss = 0.084750 psnr = 17.34 loss_mse = 0.054547 loss_lpips = 0.030204 gs_ratio = 0.781316
train step 186; scene = ['scene0642_01']; context = [[[1413, 1433]]]; loss = 0.079268 psnr = 14.56 loss_mse = 0.050604 loss_lpips = 0.028664 gs_ratio = 0.824506
train step 196; scene = ['scene0212_02']; context = [[[1414, 1439]]]; loss = 0.076745 psnr = 9.63 loss_mse = 0.048413 loss_lpips = 0.028332 gs_ratio = 0.898974
train step 206; scene = ['scene0320_02']; context = [[[2468, 2488]]]; loss = 0.078080 psnr = 11.27 loss_mse = 0.048460 loss_lpips = 0.029620 gs_ratio = 0.977231
train step 212; scene = ['scene0118_02']; context = [[[363, 379]]]; loss = 0.075896 psnr = 11.86 loss_mse = 0.050019 loss_lpips = 0.025877 gs_ratio = 0.909459
train step 222; scene = ['scene0178_00']; context = [[[1172, 1195]]]; loss = 0.072895 psnr = 13.88 loss_mse = 0.045577 loss_lpips = 0.027318 gs_ratio = 0.816785
train step 232; scene = ['scene0692_04']; context = [[[456, 479]]]; loss = 0.067276 psnr = 14.29 loss_mse = 0.039004 loss_lpips = 0.028272 gs_ratio = 0.987127
train step 242; scene = ['scene0369_01']; context = [[[934, 949]]]; loss = 0.061750 psnr = 15.59 loss_mse = 0.032675 loss_lpips = 0.029075 gs_ratio = 0.883087
train step 252; scene = ['scene0085_01']; context = [[[669, 692]]]; loss = 0.083454 psnr = 12.35 loss_mse = 0.055503 loss_lpips = 0.027951 gs_ratio = 0.887232
train step 262; scene = ['scene0680_00']; context = [[[450, 472]]]; loss = 0.063859 psnr = 13.76 loss_mse = 0.037147 loss_lpips = 0.026712 gs_ratio = 0.775843
train step 272; scene = ['scene0267_00']; context = [[[662, 677]]]; loss = 0.053178 psnr = 17.06 loss_mse = 0.026421 loss_lpips = 0.026757 gs_ratio = 0.525421
train step 282; scene = ['scene0419_00']; context = [[[3218, 3242]]]; loss = 0.061868 psnr = 12.33 loss_mse = 0.036521 loss_lpips = 0.025347 gs_ratio = 0.708827
train step 292; scene = ['scene0449_02']; context = [[[701, 719]]]; loss = 0.070924 psnr = 18.87 loss_mse = 0.045540 loss_lpips = 0.025384 gs_ratio = 0.692128
train step 302; scene = ['scene0492_00']; context = [[[216, 234]]]; loss = 0.076909 psnr = 11.99 loss_mse = 0.050956 loss_lpips = 0.025953 gs_ratio = 0.833369
train step 312; scene = ['scene0107_00']; context = [[[996, 1020]]]; loss = 0.074832 psnr = 16.54 loss_mse = 0.046203 loss_lpips = 0.028629 gs_ratio = 0.890366
train step 318; scene = ['scene0108_00']; context = [[[300, 324]]]; loss = 0.057717 psnr = 15.97 loss_mse = 0.030455 loss_lpips = 0.027262 gs_ratio = 0.985202
train step 328; scene = ['scene0313_02']; context = [[[69, 91]]]; loss = 0.062071 psnr = 15.04 loss_mse = 0.035041 loss_lpips = 0.027029 gs_ratio = 0.606440
train step 338; scene = ['scene0212_02']; context = [[[1052, 1073]]]; loss = 0.066424 psnr = 16.21 loss_mse = 0.042573 loss_lpips = 0.023851 gs_ratio = 0.909714
train step 348; scene = ['scene0293_01']; context = [[[151, 175]]]; loss = 0.054614 psnr = 16.59 loss_mse = 0.031310 loss_lpips = 0.023304 gs_ratio = 0.849380
train step 358; scene = ['scene0055_01']; context = [[[222, 247]]]; loss = 0.060802 psnr = 15.86 loss_mse = 0.037207 loss_lpips = 0.023595 gs_ratio = 0.917379
train step 368; scene = ['scene0586_00']; context = [[[170, 192]]]; loss = 0.056258 psnr = 14.56 loss_mse = 0.033254 loss_lpips = 0.023004 gs_ratio = 0.950414
train step 378; scene = ['scene0677_01']; context = [[[1114, 1135]]]; loss = 0.048317 psnr = 16.92 loss_mse = 0.024928 loss_lpips = 0.023389 gs_ratio = 0.771627
train step 388; scene = ['scene0163_00']; context = [[[1116, 1139]]]; loss = 0.067564 psnr = 13.31 loss_mse = 0.043776 loss_lpips = 0.023788 gs_ratio = 0.995481
train step 398; scene = ['scene0451_02']; context = [[[702, 719]]]; loss = 0.051043 psnr = 16.79 loss_mse = 0.027042 loss_lpips = 0.024001 gs_ratio = 0.778463
train step 408; scene = ['scene0029_02']; context = [[[1624, 1644]]]; loss = 0.045179 psnr = 16.33 loss_mse = 0.022716 loss_lpips = 0.022463 gs_ratio = 0.823229
train step 418; scene = ['scene0320_02']; context = [[[720, 736]]]; loss = 0.059597 psnr = 14.86 loss_mse = 0.035499 loss_lpips = 0.024099 gs_ratio = 0.659869
train step 424; scene = ['scene0408_00']; context = [[[1190, 1213]]]; loss = 0.048818 psnr = 14.08 loss_mse = 0.026130 loss_lpips = 0.022688 gs_ratio = 0.792094
train step 434; scene = ['scene0692_04']; context = [[[756, 774]]]; loss = 0.045340 psnr = 16.19 loss_mse = 0.022543 loss_lpips = 0.022797 gs_ratio = 0.933067
train step 444; scene = ['scene0178_00']; context = [[[751, 774]]]; loss = 0.052233 psnr = 17.65 loss_mse = 0.031421 loss_lpips = 0.020813 gs_ratio = 0.787394
train step 454; scene = ['scene0182_01']; context = [[[157, 182]]]; loss = 0.044445 psnr = 16.44 loss_mse = 0.022185 loss_lpips = 0.022260 gs_ratio = 0.972483
train step 464; scene = ['scene0323_00']; context = [[[306, 321]]]; loss = 0.047066 psnr = 12.74 loss_mse = 0.024865 loss_lpips = 0.022201 gs_ratio = 0.562403
train step 474; scene = ['scene0293_01']; context = [[[656, 675]]]; loss = 0.047717 psnr = 17.37 loss_mse = 0.025819 loss_lpips = 0.021898 gs_ratio = 0.974386
train step 484; scene = ['scene0548_02']; context = [[[3628, 3645]]]; loss = 0.052843 psnr = 14.72 loss_mse = 0.031525 loss_lpips = 0.021318 gs_ratio = 0.810315
train step 494; scene = ['scene0564_00']; context = [[[795, 813]]]; loss = 0.048878 psnr = 19.11 loss_mse = 0.027380 loss_lpips = 0.021498 gs_ratio = 0.881727
train step 504; scene = ['scene0449_02']; context = [[[76, 94]]]; loss = 0.058198 psnr = 17.01 loss_mse = 0.037046 loss_lpips = 0.021153 gs_ratio = 0.663506
train step 514; scene = ['scene0108_00']; context = [[[14, 33]]]; loss = 0.057118 psnr = 13.11 loss_mse = 0.035044 loss_lpips = 0.022075 gs_ratio = 0.841639
train step 524; scene = ['scene0214_01']; context = [[[549, 566]]]; loss = 0.056922 psnr = 16.00 loss_mse = 0.033337 loss_lpips = 0.023585 gs_ratio = 0.975861
train step 530; scene = ['scene0332_00']; context = [[[1672, 1693]]]; loss = 0.040582 psnr = 20.80 loss_mse = 0.019496 loss_lpips = 0.021086 gs_ratio = 0.863263
train step 540; scene = ['scene0297_00']; context = [[[598, 615]]]; loss = 0.046640 psnr = 19.02 loss_mse = 0.024254 loss_lpips = 0.022385 gs_ratio = 0.756836
train step 550; scene = ['scene0281_00']; context = [[[1151, 1166]]]; loss = 0.042693 psnr = 18.48 loss_mse = 0.020732 loss_lpips = 0.021961 gs_ratio = 0.748891
train step 560; scene = ['scene0067_01']; context = [[[144, 160]]]; loss = 0.042041 psnr = 17.84 loss_mse = 0.020781 loss_lpips = 0.021260 gs_ratio = 0.938380
train step 570; scene = ['scene0536_01']; context = [[[767, 789]]]; loss = 0.040344 psnr = 15.34 loss_mse = 0.019550 loss_lpips = 0.020793 gs_ratio = 0.975863
train step 580; scene = ['scene0303_01']; context = [[[292, 311]]]; loss = 0.033844 psnr = 21.18 loss_mse = 0.013584 loss_lpips = 0.020260 gs_ratio = 0.741419
train step 590; scene = ['scene0287_00']; context = [[[661, 682]]]; loss = 0.046800 psnr = 17.12 loss_mse = 0.024777 loss_lpips = 0.022023 gs_ratio = 0.744982
train step 600; scene = ['scene0408_00']; context = [[[1420, 1436]]]; loss = 0.048755 psnr = 16.77 loss_mse = 0.028725 loss_lpips = 0.020030 gs_ratio = 0.815748
train step 610; scene = ['scene0501_01']; context = [[[1811, 1826]]]; loss = 0.036236 psnr = 19.93 loss_mse = 0.017535 loss_lpips = 0.018702 gs_ratio = 0.728666
train step 620; scene = ['scene0642_01']; context = [[[3618, 3642]]]; loss = 0.054511 psnr = 14.78 loss_mse = 0.033384 loss_lpips = 0.021127 gs_ratio = 0.944300
train step 630; scene = ['scene0586_00']; context = [[[937, 955]]]; loss = 0.035055 psnr = 18.92 loss_mse = 0.014840 loss_lpips = 0.020216 gs_ratio = 0.884483
train step 636; scene = ['scene0350_01']; context = [[[1289, 1312]]]; loss = 0.046794 psnr = 17.73 loss_mse = 0.024838 loss_lpips = 0.021956 gs_ratio = 0.921824
train step 646; scene = ['scene0410_01']; context = [[[319, 339]]]; loss = 0.036465 psnr = 17.63 loss_mse = 0.016577 loss_lpips = 0.019888 gs_ratio = 0.959684
train step 656; scene = ['scene0429_00']; context = [[[721, 740]]]; loss = 0.039070 psnr = 17.80 loss_mse = 0.018517 loss_lpips = 0.020553 gs_ratio = 0.861722
[2024-10-10 15:31:36,799][py.warnings][WARNING] - /home/wang/anaconda3/envs/ps/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...